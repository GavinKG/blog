<!DOCTYPE html>
<html lang='cn'>

<head>
  <meta name="generator" content="Hexo 5.4.1">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>离轴透视投影 (Off-axis Perspective Projection) 的应用——场景放大、超分辨率截图、镜面/传送门渲染 - malos-blog</title>

  
    <meta name="description" content="题图为游戏《A Plague Tale: Innocence》的女主 Amicia。这张截图是我使用 NVIDIA Ansel 超级分辨率功能截取得到的，该功能即使用了这篇文章介绍的内容：离轴透视投影。">
<meta property="og:type" content="article">
<meta property="og:title" content="离轴透视投影 (Off-axis Perspective Projection) 的应用——场景放大、超分辨率截图、镜面&#x2F;传送门渲染">
<meta property="og:url" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/index.html">
<meta property="og:site_name" content="malos-blog">
<meta property="og:description" content="题图为游戏《A Plague Tale: Innocence》的女主 Amicia。这张截图是我使用 NVIDIA Ansel 超级分辨率功能截取得到的，该功能即使用了这篇文章介绍的内容：离轴透视投影。">
<meta property="og:locale">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/banner.jpg">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/image-20211226224839906.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/image-20211226225641377.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/image-20211226231046030.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/scenemag-zoom-preview.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/scenemag-zoom-frustum.png">
<meta property="og:image" content="https://github.com/GavinKG/SceneMagnifier/raw/master/banner.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/portal.png">
<meta property="og:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/portal-unity-visualize.jpg">
<meta property="article:published_time" content="2022-01-04T16:00:00.000Z">
<meta property="article:modified_time" content="2022-03-22T04:12:49.813Z">
<meta property="article:author" content="Gavin_KG">
<meta property="article:tag" content="渲染">
<meta property="article:tag" content="Unity">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://gavinkg.github.io/blog/%E7%A6%BB%E8%BD%B4%E9%80%8F%E8%A7%86%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8/banner.jpg">
  
  

  <!-- feed -->
  
    <link rel="alternate" href="/blog/atom.xml" title="malos-blog" type="application/atom+xml">
  

  
    
<link rel="stylesheet" href="/blog/css/main.css">

  

  

  
</head>

<body>
  


  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="title" href="/blog/"><div class="main">malos-blog</div><div class="sub cap">邪恶马洛斯的审判之地</div></a></div>
<nav class="menu dis-select"><a class="nav-item active" href="/blog/">博客</a><a class="nav-item" href="/blog/about/">关于</a></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-1-%E5%89%8D%E8%A8%80"><span class="toc-text">Part.1 前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-2-%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80"><span class="toc-text">Part.2 实现基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-3-%E5%BA%94%E7%94%A8"><span class="toc-text">Part.3 应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%9D%97%E6%B8%B2%E6%9F%93%EF%BC%9A%E5%9C%BA%E6%99%AF%E6%94%BE%E5%A4%A7%E3%80%81%E5%B1%8F%E5%B9%95%E9%98%B5%E5%88%97%E6%B8%B2%E6%9F%93%E5%92%8C%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87%E6%88%AA%E5%9B%BE"><span class="toc-text">分块渲染：场景放大、屏幕阵列渲染和高分辨率截图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%95%9C%E9%9D%A2-%E4%BC%A0%E9%80%81%E9%97%A8%E6%B8%B2%E6%9F%93%E6%96%B0%E6%96%B9%E6%A1%88%EF%BC%88%E4%BD%BF%E7%94%A8-Render-Texture%EF%BC%89"><span class="toc-text">镜面&#x2F;传送门渲染新方案（使用 Render Texture）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-4-%E5%90%8E%E8%AE%B0"><span class="toc-text">Part.4 后记</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-text">参考资料</span></a></li></ol></div></div></div>


</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" title="GitHub" href="https://github.com/GavinKG" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.3/social/08a41b181ce68.svg"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/blog/">malos-blog</a><span class="sep"></span><a class="cap breadcrumb" href="/blog/">文章</a></div><div id="post-meta">发布于&nbsp;<time datetime="2022-01-04T16:00:00.000Z">2022-01-05</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>离轴透视投影 (Off-axis Perspective Projection) 的应用——场景放大、超分辨率截图、镜面/传送门渲染</span></h1>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="banner.jpg" alt="banner"></p>
<p>题图为游戏《A Plague Tale: Innocence》的女主 Amicia。这张截图是我使用 NVIDIA Ansel 超级分辨率功能截取得到的，该功能即使用了这篇文章介绍的内容：离轴透视投影。</p>
<span id="more"></span>
<p>使用 Unity 演示。</p>
<h2 id="Part-1-前言"><a href="#Part-1-前言" class="headerlink" title="Part.1 前言"></a>Part.1 前言</h2><p>前些天刚玩通一款独立游戏《笼中窥梦》，惊叹于作者塑造的精致箱庭世界以及开发团队之小的同时，作为 Game Designer，当然是对这款游戏中驱动玩法的，诸多打破常理的画面的渲染原理非常感兴趣，正好自己最近也在着手制作一些类传送门元素的关卡设计，于是提笔写下了这篇技术笔记分享给大家。</p>
<h2 id="Part-2-实现基础"><a href="#Part-2-实现基础" class="headerlink" title="Part.2 实现基础"></a>Part.2 实现基础</h2><p>还记得在引擎中调整摄像机的时候，我们都需要调节哪些参数吗？其实除了位置渲染这些信息（决定观察者坐标系），剩下的就是 FOV、横纵比和远近裁切平面了（不考虑物理摄像机）。FOV 决定着视野的宽阔程度，横纵比决定着屏幕比例，远近裁切平面之间的物体会被显示。这两大参数可以用来生成出我们再熟悉不过的投影矩阵（Projection Matrix，以 OpenGL 约定为例，不同图形 API 的约定差异可以参考<a href="https://gavinkg.github.io/ILearnVulkanFromScratch-CN/mdroot/%E6%A6%82%E5%BF%B5%E6%B1%87%E6%80%BB/%E4%B8%8D%E5%90%8C%E5%9B%BE%E5%BD%A2%20API%20%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB.html">我的这篇笔记</a>[5]）：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{cccc} { \dfrac{cot\dfrac{fovy}{2}}{aspect} } & 0 & 0 & 0 \\ 0 & { cot \dfrac{fovy}{2} } & 0 & 0 \\ 0 & 0 & -{\dfrac{f+n}{f-n}} & -{\dfrac{2fn}{f-n}}\\ 0 & 0 & -1& 0\\ \end{array}\right]</script><p>其中 <em>fovy</em> 代表纵向延展的 FOV 值，<em>aspect</em> 为横纵比（长/宽），<em>n</em> (near) 和 <em>f</em> (far) 分别代表了近平面和远平面到观察者的最短距离，其形成了一个平截头体，我们称为视锥（View Frustum）。其在图形库和引擎中也有对应的 API：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// from https://github.com/g-truc/glm</span></span><br><span class="line"><span class="comment">// 4 params are needed: [FOV], [Aspect Ratio], [Near Plane], [Far Plane]</span></span><br><span class="line">glm::mat4 Projection = glm::<span class="built_in">perspective</span>(glm::<span class="built_in">pi</span>&lt;<span class="type">float</span>&gt;() * <span class="number">0.25f</span>, <span class="number">4.0f</span> / <span class="number">3.0f</span>, <span class="number">0.1f</span>, <span class="number">100.f</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// https://docs.unity3d.com/ScriptReference/Matrix4x4.Perspective.html</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Matrix4x4 <span class="title">Perspective</span>(<span class="params"><span class="built_in">float</span> fov, <span class="built_in">float</span> aspect, <span class="built_in">float</span> zNear, <span class="built_in">float</span> zFar</span>)</span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PerspectiveMatrix.h:40 (UE 4.27.2)</span></span><br><span class="line"><span class="built_in">FPerspectiveMatrix</span>(<span class="type">float</span> HalfFOV, <span class="type">float</span> Width, <span class="type">float</span> Height, <span class="type">float</span> MinZ, <span class="type">float</span> MaxZ);</span><br></pre></td></tr></table></figure>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="image-20211226224839906.png" alt="image-20211226224839906"></p>
<p>但其实我们一直在做一个假设，就是<strong>观察者位置投影到成像平面（近平面）的视点位置即为近平面中心点</strong>，一切的透视关系都按照屏幕中心进行“缩放”，如上图所示[1]。这确实没错，大多数情况下人眼都会看不出区别，我们也已经适应了屏幕成像的样子。但其实在很多情况下，<strong>观察者位置投影到成像平面的视点位置并不恰好是屏幕中心</strong>，因此看到的画面其实是不符合观察者虚拟位置近大远小的透视关系的（想象你从侧面看一张照片，你看到照片里的物体的样子会在生活中出现吗），这种情况如果希望依然维持正确的透视关系，我们需要同步视点中心到透视投影矩阵中，即产生<strong>离轴透视投影 (Off-axis Perspective Projection)</strong> ，如下图所示[1]</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="image-20211226225641377.png" alt="image-20211226225641377"></p>
<p>其实通过两者产生的视锥体也能看出端倪：我们最常见的视锥体，近平面中心点到远平面中心点的连线是垂直于这两个平面的，但离轴投影则不会垂直。这种情况下我们就不能通过常见的 FOV 和横纵比来描述摄像机了。幸好这个投影矩阵也可以直接根据<strong>近平面上下左右四条边到观察者在近平面上的投影点的距离</strong>，加上远近平面距离观察者的最小距离来推导：</p>
<script type="math/tex; mode=display">
\left[\begin{array}{cccc} { \dfrac{2n}{ r-l } } & 0 & { \dfrac{r + l} { r-l } } & 0 \\ 0 & { \dfrac{2n}{ t-b } } & { \dfrac{t + b}{ t-b } } & 0 \\ 0 & 0 & -{\dfrac{f+n}{f-n}} & -{\dfrac{2fn}{f-n}}\\ 0 & 0 & -1& 0\\ \end{array}\right]</script><blockquote>
<p> 复习一下：投影矩阵的推导其实非常简单，其需要做的就有三点：1. 让最终齐次坐标的 $w=-z$，供之后的透视除法使用，即最后一行的 -1；2. 将观察空间 z 值从 [n, f] 映射到 [-1, 1] 区间中；3. 将观察空间 x, y 也从 [l, r] 和 [b, t] 限制到 [-1, 1] 区间中。直接上图巩固记忆（OpenGL 约定）[3]：</p>
<p> <img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="image-20211226231046030.png" alt="image-20211226231046030"></p>
</blockquote>
<p>图形库和 Unity 引擎依然有对应的 API：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// OpenGL builtin API</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">glFrustum</span><span class="params">(GLdouble left, GLdouble right, GLdouble bottom, GLdouble top, GLdouble zNear, GLdouble zFar)</span></span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Unity</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Matrix4x4 <span class="title">Frustum</span>(<span class="params"><span class="built_in">float</span> left, <span class="built_in">float</span> right, <span class="built_in">float</span> bottom, <span class="built_in">float</span> top, <span class="built_in">float</span> zNear, <span class="built_in">float</span> zFar</span>)</span>;</span><br></pre></td></tr></table></figure>
<p>我们可以直接使用其提供的 API，或者手动构建一个矩阵（UE 暂时没找到；直接编码到矩阵时需注意不同平台和引擎的差别，例如图形 API 区别、是否使用 Reversed-Z 等等）设置为摄像机的投影矩阵。此时观察者位置在成像平面上的投影点即为新的“透视缩放点”，一切将以观察者位置（而不是成像平面中心）产生近大远小的透视关系。</p>
<h2 id="Part-3-应用"><a href="#Part-3-应用" class="headerlink" title="Part.3 应用"></a>Part.3 应用</h2><p>啰啰嗦嗦讲了那么多原理（其实都是现成的 API），下面来看看离轴透视投影到底能用在哪些地方吧：</p>
<h3 id="分块渲染：场景放大、屏幕阵列渲染和高分辨率截图"><a href="#分块渲染：场景放大、屏幕阵列渲染和高分辨率截图" class="headerlink" title="分块渲染：场景放大、屏幕阵列渲染和高分辨率截图"></a>分块渲染：场景放大、屏幕阵列渲染和高分辨率截图</h3><p>有些时候我们希望把自己制作的游戏画面截出一张高分辨率截图收藏起来，又或者我们想“矢量”放大场景中的某个部分，又或者我们在组建一个高分辨率屏幕阵列渲染一个视口，然而一台计算机的图形算力并不能撑住屏幕阵列的渲染。解决上述问题即为离轴透视的第一个用途：<strong>渲染一个“正常”视锥体的一个子视锥，即分块渲染</strong>。</p>
<blockquote>
<p>对于高分辨率截图来说，由于显卡存在着 2D Texture 的最大长宽限制（一般为 16384 像素，感兴趣的同学可以去看 DX12 中的 <code>D3D12_REQ_TEXTURE2D_U_OR_V_DIMENSION</code> 和 Vulkan 中的 <code>maxImageDimension2D</code>），截图分辨率不能无限大下去。在 UE4 高分辨率截图源码中也能看到，当截图分辨率超过上述限制（<code>GetMax2DTextureDimension</code> 方法）时，截图会失败。还有一个原因是，如果一次渲染超高分辨率，显存资源可能不够用（例如GBuffer），并且驱动可能会因为单个渲染任务耗费时间过长而重启设备。</p>
</blockquote>
<p>首先要清楚的是，我们并不能通过新建一个相机，改一改 FOV 并旋转它到新的角度达到渲染场景的某个部分，因为我们所有的子视锥的成像平面依然是一个……呃……平面，近平面远平面必须分别在同一个平面上，才能构建出原始视锥的子视锥。当然我们如果组建球面屏幕的话这么做是可以的，即让每一块屏幕渲染球面的一个立体角。</p>
<p>子视锥的构建其实很简单：在近平面和远平面上都切出位置比例相同的矩形，对应点连接起来构成新的子视锥，如下图所示。此时如果矩形中心不恰好是远近平面中心的话，就满足了上述离轴透视的条件：观察者在近平面投影点不是新的近平面矩形的中心点，毕竟观察者的投影点没有变化，即<strong>我依然希望透视关系根据观察者位置进行近大远小</strong>。此时虽然场景被放大了，但透视关系没有变，就像在图片查看器中放大一张图一样。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="scenemag-zoom-preview.png" alt="scenemag-zoom-preview"></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="scenemag-zoom-frustum.png" alt="scenemag-zoom-frustum"></p>
<p>我们可以直接根据偏移位置计算得到新的近平面矩形上下左右四条边到投影点的距离，代码可以参考我做的一个场景放大器 Unity Demo 工程：<a target="_blank" rel="noopener" href="https://github.com/GavinKG/SceneMagnifier。">https://github.com/GavinKG/SceneMagnifier。</a></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://github.com/GavinKG/SceneMagnifier/raw/master/banner.png" alt=""></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// range from (-1, -1) to (1, 1) inclusive, with (-1, -1) being screen&#x27;s lower-left, and (1, 1) being screen&#x27;s upper-right</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetMagnifyRegion</span><span class="params">(<span class="type">float</span> xmin, <span class="type">float</span> ymin, <span class="type">float</span> xmax, <span class="type">float</span> ymax)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// Retrive camera properties</span></span><br><span class="line">    <span class="type">float</span> n = camera.nearClipPlane;</span><br><span class="line">    <span class="type">float</span> f = camera.farClipPlane;</span><br><span class="line">    <span class="type">float</span> fovy = camera.fieldOfView; <span class="comment">// in degrees, uses verticle fov (fovy)</span></span><br><span class="line">    <span class="type">float</span> aspect = camera.aspect; <span class="comment">// width / height</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Calculate l, r, b, t</span></span><br><span class="line">    <span class="type">float</span> ogT = Mathf.<span class="built_in">Tan</span>(fovy / <span class="number">2f</span> * Mathf.Deg2Rad) * n;</span><br><span class="line">    <span class="type">float</span> ogR = ogT * aspect;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> l = ogR * xmin;</span><br><span class="line">    <span class="type">float</span> r = ogR * xmax;</span><br><span class="line">    <span class="type">float</span> b = ogT * ymin;</span><br><span class="line">    <span class="type">float</span> t = ogT * ymax;</span><br><span class="line"></span><br><span class="line">    Matrix4x4 persp = Matrix4x4.<span class="built_in">Frustum</span>(l, r, b, t, n, f);</span><br><span class="line">    camera.projectionMatrix = persp;</span><br><span class="line">    camera.cullingMatrix = persp * camera.worldToCameraMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>直接上视频：</p>
<p><a href="Scene-Magnifier-Showcase-x264.mp4">&gt;&gt; 视频链接 - 场景放大器效果 &lt;&lt;</a></p>
<p><a href="Scene-Magnifier-Visualize-x264.mp4">&gt;&gt; 视频链接 - 场景放大器原理 &lt;&lt;</a></p>
<p>有了这些代码，做高分辨率截图就很容易了。我们可以将屏幕等分为 m x n 块，对于每块分别渲染保存为位图，再使用外部软件将其合并，避开一次不能渲染太大尺寸纹理的硬件限制。</p>
<blockquote>
<p>当然这么做有一点不能避开的是后处理。由于一般情况下，一些后处理根据全屏覆盖的四边形UV进行计算（例如暗角），因此需要加以修改从而使得此类后处理应用于整个阵列而不是每个分块。一些需要采样临近像素，甚至在整个屏幕空间做 Ray Marching 求交的效果，可能都会失效（例如 SSR 在分块接缝处可能会有明显的断裂）。在工程中我们可以将每个分块些许增大，并后期剪裁，多留一些屏幕空间信息给屏幕空间算法，或者分块时让两块之间相互重叠，后期在分块重叠部分中渐变过渡（NVIDIA Ansel 采取的方案）。但这都算不上完美的解决方案。</p>
</blockquote>
<p>同理，对于屏幕阵列渲染来说，我们可以将每一块/几块屏幕交给一台计算机进行渲染，并使用离轴透视进行相机投影矩阵的配置。可以看到，上述代码对相机的 culling matrix 也进行了设置，因此每台计算机在渲染时，输送进 GPU 的图元也是<strong>经过良好的视锥剔除的</strong>。</p>
<h3 id="镜面-传送门渲染新方案（使用-Render-Texture）"><a href="#镜面-传送门渲染新方案（使用-Render-Texture）" class="headerlink" title="镜面/传送门渲染新方案（使用 Render Texture）"></a>镜面/传送门渲染新方案（使用 Render Texture）</h3><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="portal.png" alt="portal"></p>
<p>游戏中经常会有全反射的镜子，以及传送门元素的渲染，例如大名鼎鼎的《Portal》系列。镜面/传送门渲染的方法很多，其中<strong>使用 Stencil Buffer</strong> 标记传送门区域，然后开启 Stencil Test 渲染镜面/传送门的方法比较流行，因为其直接在屏幕空间进行传送门内部的渲染，能够做到 pixel-perfect（下称“Stencil 方案”）。类似的也有<strong>让反射/传送门相机渲染出一张全屏的纹理</strong>，然后在反射物体着色时，片元着色器中<strong>直接使用屏幕空间坐标采样那张全屏纹理</strong>（下称“全屏 RT 方案”）。</p>
<p>我这里介绍的是另一种方法，即同样使用 Render Texture，<strong>但直接将该纹理直接应用于传送门的材质中</strong>（即“贴在物体上”）采样输出（下称“本方案”）。</p>
<p>当然，本方案远没有想象的那么简单。除了需要将传送门的相机摆放在正确的位置外，我们也需要考虑下面几个问题：</p>
<ol>
<li>由于没有 Stencil Mask 辅助标记屏幕空间的呈现区域，因此 RT 摄像机渲染出来的区域<strong>必须和传送门显示的完全一致</strong>。否则即使不在乎渲染浪费，我们也不知道怎么计算出该显示的区域。</li>
<li><strong>RT 摄像机的近平面必须为传送门所在平面</strong>，不然会被近平面裁切，导致渲染不全。</li>
<li>本方案渲染出的 Render Texture <strong>将会呈现在传送门物体切线空间中</strong>，而并不直接是屏幕空间中。</li>
</ol>
<p>如果把主摄像机（透视投影）当成上例中人眼，传送门物体当成上例中显示器的话，此时在主摄像机（透视投影）倾斜着看传送门物体，就能够类比人眼倾斜着看屏幕的情况，<strong>可以直接用上述离轴透视投影矩阵来纠正</strong>，解决了第三点。同时，采用离轴透视就意味着把传送门平面当成成像平面，因此传送门摄像机的前方向就要与目标传送门垂直，并且旋转和目标传送门一致，此时只需要调整近平面距离即可让近平面矩形和传送门显示矩形完全一致，解决了第二点，再通过数学运算算出摄像机最终位置，让其成像恰好为传送门需要显示出来的即可。如下图所示：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="portal-unity-visualize.jpg" alt="portal-unity-visualize"></p>
<blockquote>
<p>这里也顺带说一下，如果使用 Stencil 方案和全屏幕 RT 方案，同样可以使用 Oblique Near-plane Projection 的方法，将近平面变成目标传送门平面，来避免被后墙遮挡和近处被裁切的现象发生。Unity 直接提供了 <code>Camera.CalculateObliqueMatrix</code> 方法，可以直接设置一个自定义近平面。</p>
</blockquote>
<p>同样，这里给出计算摄像机位置，旋转，以及离轴透视投影矩阵的核心代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetupPortalCamera</span><span class="params">(PortalConnectionInfo connectionInfo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Vector3 camPos = ViewCamera.transform.position;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Find target camera&#x27;s rotation (same as target portal)</span></span><br><span class="line">    Quaternion targetCamRot = connectionInfo.targetPortal.transform.rotation;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Find target camera&#x27;s position</span></span><br><span class="line">    Vector3 camPosLS = connectionInfo.sourcePortal.transform.<span class="built_in">InverseTransformPoint</span>(camPos);</span><br><span class="line">    camPosLS.z *= <span class="number">-1</span>; <span class="comment">// mirror-like</span></span><br><span class="line">    Vector3 targetCamPos = connectionInfo.targetPortal.transform.<span class="built_in">TransformPoint</span>(camPosLS);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Figure out perspective projection&#x27;s center point on near plane</span></span><br><span class="line">    Plane nearPlane = <span class="keyword">new</span> <span class="built_in">Plane</span>(connectionInfo.targetPortal.FacingDirection, connectionInfo.targetPortal.transform.position); <span class="comment">// the target portal&#x27;s sitting plane, therefore becoming portal camera&#x27;s near plane</span></span><br><span class="line">    Vector3 centerPointWS = nearPlane.<span class="built_in">ClosestPointOnPlane</span>(targetCamPos); <span class="comment">// find the center point</span></span><br><span class="line">    Vector3 centerPointLS = connectionInfo.targetPortal.transform.<span class="built_in">InverseTransformPoint</span>(centerPointWS); <span class="comment">// x, y should be the offset for the frustum</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Calculate the off-axis projection matrix</span></span><br><span class="line">    <span class="type">float</span> far = ViewCamera.farClipPlane;</span><br><span class="line">    <span class="type">float</span> near = Vector3.<span class="built_in">Distance</span>(centerPointWS, targetCamPos);</span><br><span class="line">    <span class="type">float</span> left = connectionInfo.sourcePortal.LocalUpperLeftCorner.x - centerPointLS.x;</span><br><span class="line">    <span class="type">float</span> right = connectionInfo.sourcePortal.LocalUpperRightCorner.x - centerPointLS.x;</span><br><span class="line">    <span class="type">float</span> top = connectionInfo.sourcePortal.LocalUpperLeftCorner.y - centerPointLS.y;</span><br><span class="line">    <span class="type">float</span> bottom = connectionInfo.sourcePortal.LocalLowerLeftCorner.y - centerPointLS.y;</span><br><span class="line">    Matrix4x4 proj = Matrix4x4.<span class="built_in">Frustum</span>(left, right, bottom, top, near, far);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Apply to the camera object</span></span><br><span class="line">    connectionInfo.cameraObject.transform.position = targetCamPos;</span><br><span class="line">    connectionInfo.cameraObject.transform.rotation = targetCamRot;</span><br><span class="line">    Camera portalCamera = connectionInfo.cameraObject.<span class="built_in">GetComponent</span>&lt;Camera&gt;();</span><br><span class="line">    portalCamera.projectionMatrix = proj;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Let Unity draw camera&#x27;s frustum correctly...</span></span><br><span class="line">    portalCamera.nearClipPlane = near;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Portal culling</span></span><br><span class="line">    portalCamera.cullingMatrix = proj * portalCamera.worldToCameraMatrix;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 Shader 中采样纹理时，别忘了做水平镜面翻转，类似于：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">float4 frag(Varyings IN) : SV_TARGET</span><br><span class="line">&#123;</span><br><span class="line">    IN.uv.x  = 1 - IN.uv.x; // mirror-invert</span><br><span class="line">    return SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, IN.uv);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出，该矩阵同样作为了传送门摄像机的 Culling Matrix。由于传送门摄像机的视锥必须刚刚好设成传送门的渲染范围，因此<strong>该矩阵作为剔除矩阵进行视锥体剔除相当高效</strong>，在使用其它方案渲染镜面和传送门时也可以用该矩阵进行视锥剔除。</p>
<p>关于传送门切线空间计算和摆放等与渲染无关的细节将不再此处赘述，可以前往 <a target="_blank" rel="noopener" href="https://github.com/GavinKG/Portal-Rendering-Demo-using-Off-Axis-Perspective-Projection">https://github.com/GavinKG/Portal-Rendering-Demo-using-Off-Axis-Perspective-Projection</a> 下载示例工程和源码，其包含一个使用本方案的 FPS 传送门的摆放和渲染实现。直接上视频：</p>
<p>（前者为场景传送门演示，后者为原理）</p>
<p><a href="Portal-Unity-Showcase-x264.mp4">&gt;&gt; 视频链接 - 传送门效果 &lt;&lt;</a></p>
<p><a href="Portal-Unity-Visualize-x264.mp4">&gt;&gt; 视频链接 - 传送门渲染原理 &lt;&lt;</a></p>
<blockquote>
<p>其实本方案相较于 Stencil 方案来渲染传送门/镜面反射存在诸多劣势，但也有其无可替代的地方。本方案中 RT 由于应用于传送门模型表面，从纹素到像素颜色信息注定会被插值，因此无法做到 pixel-perfect。同时由于 RT 每帧做 Runtime Mipmap 生成的开销比较大，如果不存在 mipmaps 的话，无法做到纹理的三线性/各向异性过滤，违反了采样定理，在极端角度上看传送门效果会非常惨烈。但全屏 RT 方案和本方案首先<strong>实现简单</strong>（这点在实际的商业项目中真的很重要），在现有的支持多相机的渲染管线下（例如 Unity 和 UE 自带的渲染管线），不用改管线就可以做到完美的渲染实现（Stencil 方案在做递归渲染传送门时可能需要配合管线的修改以实现最大性能），并且可以很方便低降分辨率。同时，由于 RT 最终是被传送门模型当成一张普通的纹理进行采样，因此那些<strong>使用 UV 的特效依然可以使用在传送门上</strong>，例如传送门的扭曲、扰动（类似水面的反射渲染）效果。全屏 RT 方案和本方案<strong>渲染传送门前面的半透明物体也不用多做考虑</strong>，然而使用 Stencil 方案，在渲染完传送门内部之后才能够渲染外部的透明物体，依然需要渲染管线本身的支持。甚至在实际项目中，<strong>有些时候 Stencil Buffer 被用来做其它工作了</strong>，在宝贵的 GBuffer 里单独为镜面开一张 Stencil 也不划算，因此使用 RT 则成为了最优解。</p>
<p>全屏 RT 方案和 Stencil 方案原理没什么本质上的区别，也具有上述使用 RT 的一些优势，但可能存在浪费渲染的情况，因此一般用于大型水体、大型镜面和地面假反光的渲染上。此处如果使用 RT 渲染小型镜面、传送门时使用本文实现方法性能会更佳。</p>
</blockquote>
<h2 id="Part-4-后记"><a href="#Part-4-后记" class="headerlink" title="Part.4 后记"></a>Part.4 后记</h2><p>当然，离轴透视投影的应用还有很多，例如 VR 双眼的离轴透视矫正，以及 AR 中使用离轴透视投影（类似于传送门渲染）[4] 等。离轴透视投影本身并不难，但用好它能够创造出很多有意思的应用场景。找到这些点子并成功应用在游戏设计中也会是 Game Designer 工作中最开心的地方之一吧。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><p>图出处：</p>
<p><a target="_blank" rel="noopener" href="http://160592857366.free.fr/joe/ebooks/ShareData/Generalized%20Perspective%20Projection.pdf">http://160592857366.free.fr/joe/ebooks/ShareData/Generalized%20Perspective%20Projection.pdf</a></p>
</li>
<li><p>OpenGL 中的 <code>glFrustum</code> 方法：</p>
<p><a target="_blank" rel="noopener" href="https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/glFrustum.xml">https://www.khronos.org/registry/OpenGL-Refpages/gl2.1/xhtml/glFrustum.xml</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/windows/win32/opengl/glfrustum">https://docs.microsoft.com/en-us/windows/win32/opengl/glfrustum</a></p>
</li>
<li><p>Scratchapixel 推导透视矩阵，权当复习一下：</p>
<p><a target="_blank" rel="noopener" href="https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/building-basic-perspective-projection-matrix">https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/building-basic-perspective-projection-matrix</a></p>
<p><a target="_blank" rel="noopener" href="https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix">https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix</a></p>
</li>
<li><p>AR 中的应用，这个确实太炫酷了：</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@michel.brisis/off-axis-projection-in-unity-1572d826541e">https://medium.com/@michel.brisis/off-axis-projection-in-unity-1572d826541e</a></p>
</li>
<li><p>不同图形 API 之间约定区别（OpenGL/Direct3D/Vulkan/Metal）：</p>
<p><a href="https://gavinkg.github.io/ILearnVulkanFromScratch-CN/mdroot/%E6%A6%82%E5%BF%B5%E6%B1%87%E6%80%BB/%E4%B8%8D%E5%90%8C%E5%9B%BE%E5%BD%A2%20API%20%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB.html">https://gavinkg.github.io/ILearnVulkanFromScratch-CN/mdroot/%E6%A6%82%E5%BF%B5%E6%B1%87%E6%80%BB/%E4%B8%8D%E5%90%8C%E5%9B%BE%E5%BD%A2%20API%20%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB.html</a></p>
</li>
</ol>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/blog/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%A4%84%E7%90%86%E5%B9%B6%E5%89%AA%E8%BE%91%20PS5%20%E5%86%85%E5%BD%95%E8%A7%86%E9%A2%91%E7%B4%A0%E6%9D%90/">如何快速处理 PS5 录制的 HDR 视频素材并剪辑<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/blog/UE4%20%E5%AE%9E%E7%8E%B0%E5%A4%9A%E9%A2%9C%E8%89%B2%E6%8F%8F%E8%BE%B9+%E9%81%AE%E6%8C%A1%E9%AB%98%E4%BA%AE/">UE4 实现多颜色描边+遮挡高亮，以及移动端效果/性能分析（踩坑实录）<span class="note">较新</span></a><div class="line"></div><a id="more" href="/blog/archives">检索全部文章</a></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="GavinKG/blog-comments" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="https://gavinkg.github.io/blog/blog/">@Gavin_KG</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.5.1" title="v1.5.1">Stellar</a> 作为主题。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.5.1';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/blog/js/plugins/sites.js',
    friendsjs: '/blog/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper/swiper-bundle.min.css","js":"https://unpkg.com/swiper/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://cdn.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
</script>

<!-- required -->

  
<script src="/blog/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
